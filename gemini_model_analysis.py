import pandas as pd
import numpy as np
import json
import re
from collections import Counter
from scipy import stats
from itertools import combinations
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 80)
print("GEMINI ëª¨ë¸ íŠ¹ì„± ë¶„ì„ (Model-Specific Analysis)")
print("=" * 80)
print("ëª©ì : Gemini-2.5-Pro ëª¨ë¸ì˜ ê¸°ë§Œì  ì „ëµ ì‹ë³„ íŒ¨í„´ ì‹¬ì¸µ ë¶„ì„")
print()

# --- 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
print("1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬")
print("-" * 40)

try:
    df = pd.read_csv('deception_strategy_analysis.csv')
    print(f"âœ“ ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ë ˆì´ë¸”ë§")
except FileNotFoundError:
    print("âœ— ì˜¤ë¥˜: 'deception_strategy_analysis.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

try:
    with open('final_taxonomy_mapping.json', 'r') as f:
        final_taxonomy_mapping = json.load(f)
    print(f"âœ“ ìµœì¢… ì „ëµ ë§¤í•‘ ë¡œë“œ: {len(final_taxonomy_mapping)}ê°œ ì „ëµ")
except FileNotFoundError:
    print("âœ— ì˜¤ë¥˜: 'final_taxonomy_mapping.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

def parse_json_lines(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    json_strings = re.findall(r'{.*?}', content, re.DOTALL)
    data = []
    for s in json_strings:
        try:
            data.append(json.loads(s))
        except json.JSONDecodeError:
            continue
    return data

persuasion_data = parse_json_lines('matched_sample.json')
persuasion_df = pd.DataFrame(persuasion_data)
persuasion_metric_key = 'persuasiveness_metric' if 'persuasiveness_metric' in persuasion_df.columns else 'persuasion_metric'
persuasion_df.rename(columns={'argument': 'original_argument', persuasion_metric_key: 'persuasion_metric'}, inplace=True)
persuasion_df = persuasion_df[['original_argument', 'persuasion_metric']]
print(f"âœ“ ì„¤ë“ë ¥ ë°ì´í„° ë¡œë“œ: {len(persuasion_df)}ê°œ ë…¼ì¦")

# Gemini ëª¨ë¸ ë°ì´í„°ë§Œ í•„í„°ë§
gemini_df = df[df['model'] == 'gemini-2.5-pro'].copy()
print(f"âœ“ Gemini ëª¨ë¸ ë°ì´í„° í•„í„°ë§: {len(gemini_df):,}ê°œ ë ˆì´ë¸”ë§")

# ìµœì¢… ì „ëµ ë§¤í•‘
gemini_df['final_strategy'] = gemini_df['mapped_strategy'].map(final_taxonomy_mapping)
gemini_df.dropna(subset=['final_strategy'], inplace=True)
print(f"âœ“ ìµœì¢… ì „ëµ ë§¤í•‘ ì™„ë£Œ: {len(gemini_df):,}ê°œ ë ˆì´ë¸”ë§")

# ë…¼ì¦ ì»¬ëŸ¼ëª… í†µì¼ ë° ì„¤ë“ë ¥ ë°ì´í„° ë³‘í•©
if 'argument' in gemini_df.columns:
    gemini_df.rename(columns={'argument': 'original_argument'}, inplace=True)

gemini_df = pd.merge(gemini_df, persuasion_df, on='original_argument', how='left')
gemini_df['argument_id'] = pd.factorize(gemini_df['original_argument'])[0]

# **í•µì‹¬**: ì¤‘ë³µ ì œê±° - ê°™ì€ ë²„ì „ì´ ê°™ì€ ë…¼ì¦ì—ì„œ ê°™ì€ ì „ëµì„ ì—¬ëŸ¬ ë²ˆ ì–¸ê¸‰í•œ ê²½ìš°
print(f"âœ“ ì¤‘ë³µ ì œê±° ì „: {len(gemini_df):,}ê°œ ë ˆì´ë¸”ë§")
gemini_df_unique = gemini_df.drop_duplicates(subset=['argument_id', 'version', 'final_strategy'])
print(f"âœ“ ì¤‘ë³µ ì œê±° í›„: {len(gemini_df_unique):,}ê°œ ê³ ìœ  ë ˆì´ë¸”ë§")
print(f"âœ“ ì œê±°ëœ ì¤‘ë³µ: {len(gemini_df) - len(gemini_df_unique):,}ê°œ ({((len(gemini_df) - len(gemini_df_unique))/len(gemini_df)*100):.1f}%)")
print()

# --- 2. ê¸°ë³¸ í†µê³„ ë¶„ì„ ---
print("2. ê¸°ë³¸ í†µê³„ ë¶„ì„")
print("-" * 40)

total_arguments = gemini_df_unique['argument_id'].nunique()
total_versions = gemini_df_unique['version'].nunique()
total_strategies = gemini_df_unique['final_strategy'].nunique()

print(f"âœ“ ë¶„ì„ ëŒ€ìƒ ë…¼ì¦ ìˆ˜: {total_arguments}ê°œ")
print(f"âœ“ ë¶„ì„ ëŒ€ìƒ ë²„ì „ ìˆ˜: {total_versions}ê°œ (v1-v5)")
print(f"âœ“ ì‹ë³„ëœ ì „ëµ ìˆ˜: {total_strategies}ê°œ")
print()

# --- 3. ì „ëµ ì‹ë³„ íŒ¨í„´ ë¶„ì„ ---
print("3. ì „ëµ ì‹ë³„ íŒ¨í„´ ë¶„ì„")
print("-" * 40)

# 3.1 ë…¼ì¦ë³„ ì „ëµ ìˆ˜ ê³„ì‚°
strategies_per_argument = gemini_df_unique.groupby(['argument_id', 'version'])['final_strategy'].count().reset_index()
strategies_per_argument.rename(columns={'final_strategy': 'strategy_count'}, inplace=True)

# ì „ì²´ í‰ê· 
overall_mean = strategies_per_argument['strategy_count'].mean()
overall_std = strategies_per_argument['strategy_count'].std()
print(f"âœ“ ë…¼ì¦ë‹¹ í‰ê·  ì „ëµ ìˆ˜: {overall_mean:.2f} Â± {overall_std:.2f}")

# ë²„ì „ë³„ í‰ê· 
version_stats = strategies_per_argument.groupby('version')['strategy_count'].agg(['mean', 'std', 'count']).round(2)
print(f"\nâœ“ ë²„ì „ë³„ ì „ëµ ìˆ˜ í†µê³„:")
print(version_stats)

# ë²„ì „ ê°„ ì°¨ì´ í†µê³„ì  ê²€ì •
version_groups = [strategies_per_argument[strategies_per_argument['version'] == v]['strategy_count'].values 
                 for v in sorted(gemini_df_unique['version'].unique())]
f_stat, p_value = stats.f_oneway(*version_groups)
print(f"\nâœ“ ë²„ì „ ê°„ ì°¨ì´ ê²€ì • (ANOVA): F={f_stat:.3f}, p={p_value:.4f}")
if p_value < 0.05:
    print("  â†’ ë²„ì „ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ ì¡´ì¬")
else:
    print("  â†’ ë²„ì „ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ")

# ì „ëµ ë¶„í¬
strategy_distribution = strategies_per_argument['strategy_count'].value_counts().sort_index()
print(f"\nâœ“ ë…¼ì¦ë³„ ì „ëµ ìˆ˜ ë¶„í¬:")
for count, freq in strategy_distribution.items():
    percentage = (freq / len(strategies_per_argument)) * 100
    print(f"  {count}ê°œ ì „ëµ: {freq}ê°œ ì‚¬ë¡€ ({percentage:.1f}%)")
print()

# --- 4. ë²„ì „ ê°„ ì¼ê´€ì„± ë¶„ì„ ---
print("4. ë²„ì „ ê°„ ì¼ê´€ì„± ë¶„ì„")
print("-" * 40)

def calculate_jaccard_index(set1, set2):
    """ë‘ ì§‘í•©ì˜ Jaccard Index ê³„ì‚°"""
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union if union > 0 else 0

# ê° ë…¼ì¦ë³„ë¡œ ë²„ì „ ê°„ ì¼ì¹˜ë„ ê³„ì‚°
consistency_results = []
arguments = gemini_df_unique['argument_id'].unique()

for arg_id in arguments:
    arg_data = gemini_df_unique[gemini_df_unique['argument_id'] == arg_id]
    
    # ê° ë²„ì „ë³„ ì „ëµ ì§‘í•©
    version_strategies = {}
    for version in sorted(arg_data['version'].unique()):
        version_data = arg_data[arg_data['version'] == version]
        version_strategies[version] = set(version_data['final_strategy'].values)
    
    # ëª¨ë“  ë²„ì „ ìŒì— ëŒ€í•´ Jaccard Index ê³„ì‚°
    versions = list(version_strategies.keys())
    for i, v1 in enumerate(versions):
        for j, v2 in enumerate(versions):
            if i < j:  # ì¤‘ë³µ ë°©ì§€
                jaccard = calculate_jaccard_index(version_strategies[v1], version_strategies[v2])
                consistency_results.append({
                    'argument_id': arg_id,
                    'version1': v1,
                    'version2': v2,
                    'jaccard_index': jaccard
                })

consistency_df = pd.DataFrame(consistency_results)

# ì „ì²´ í‰ê·  ì¼ì¹˜ë„
mean_jaccard = consistency_df['jaccard_index'].mean()
std_jaccard = consistency_df['jaccard_index'].std()
print(f"âœ“ í‰ê·  Jaccard Index: {mean_jaccard:.3f} Â± {std_jaccard:.3f}")

# ë²„ì „ ìŒë³„ ì¼ì¹˜ë„
version_pair_consistency = consistency_df.groupby(['version1', 'version2'])['jaccard_index'].mean().round(3)
print(f"\nâœ“ ë²„ì „ ìŒë³„ í‰ê·  ì¼ì¹˜ë„:")
for (v1, v2), jaccard in version_pair_consistency.items():
    print(f"  {v1} vs {v2}: {jaccard:.3f}")

# ì¼ì¹˜ë„ ë¶„í¬
jaccard_bins = pd.cut(consistency_df['jaccard_index'], bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0], 
                     labels=['ë§¤ìš° ë‚®ìŒ(0-0.2)', 'ë‚®ìŒ(0.2-0.4)', 'ì¤‘ê°„(0.4-0.6)', 'ë†’ìŒ(0.6-0.8)', 'ë§¤ìš° ë†’ìŒ(0.8-1.0)'])
jaccard_distribution = jaccard_bins.value_counts()
print(f"\nâœ“ ì¼ì¹˜ë„ ë¶„í¬:")
for level, count in jaccard_distribution.items():
    percentage = (count / len(consistency_df)) * 100
    print(f"  {level}: {count}ê°œ ({percentage:.1f}%)")

# ì™„ì „ ì¼ì¹˜ vs ì™„ì „ ë¶ˆì¼ì¹˜ ë¶„ì„
complete_matches = (consistency_df['jaccard_index'] == 1.0).sum()
complete_mismatches = (consistency_df['jaccard_index'] == 0.0).sum()
print(f"\nâœ“ ì™„ì „ ì¼ì¹˜: {complete_matches}ê°œ ({complete_matches/len(consistency_df)*100:.1f}%)")
print(f"âœ“ ì™„ì „ ë¶ˆì¼ì¹˜: {complete_mismatches}ê°œ ({complete_mismatches/len(consistency_df)*100:.1f}%)")
print()

# --- 5. ì„¤ë“ë ¥-ì „ëµ ê´€ê³„ ë¶„ì„ ---
print("5. ì„¤ë“ë ¥-ì „ëµ ê´€ê³„ ë¶„ì„")
print("-" * 40)

# ì„¤ë“ë ¥ ì ìˆ˜ ë¶„ë¥˜ (3ë¶„ìœ„ìˆ˜ ê¸°ì¤€)
persuasion_scores = gemini_df_unique.dropna(subset=['persuasion_metric'])['persuasion_metric']
q33, q67 = persuasion_scores.quantile([0.33, 0.67])

def classify_persuasion(score):
    if pd.isna(score):
        return 'Unknown'
    elif score <= q33:
        return 'Low'
    elif score <= q67:
        return 'Medium'
    else:
        return 'High'

gemini_df_unique['persuasion_level'] = gemini_df_unique['persuasion_metric'].apply(classify_persuasion)

print(f"âœ“ ì„¤ë“ë ¥ ë¶„ë¥˜ ê¸°ì¤€:")
print(f"  Low: â‰¤ {q33:.2f}")
print(f"  Medium: {q33:.2f} < score â‰¤ {q67:.2f}")
print(f"  High: > {q67:.2f}")

# ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ë¶„í¬
persuasion_dist = gemini_df_unique['persuasion_level'].value_counts()
print(f"\nâœ“ ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ë¶„í¬:")
for level, count in persuasion_dist.items():
    percentage = (count / len(gemini_df_unique)) * 100
    print(f"  {level}: {count}ê°œ ({percentage:.1f}%)")

# ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ì „ëµ ë¶„í¬
persuasion_strategy_crosstab = pd.crosstab(gemini_df_unique['persuasion_level'], 
                                          gemini_df_unique['final_strategy'], 
                                          normalize='index') * 100

print(f"\nâœ“ ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ì „ëµ ë¶„í¬ (%):")
print(persuasion_strategy_crosstab.round(1))

# ì¹´ì´ì œê³± ê²€ì •
contingency_table = pd.crosstab(gemini_df_unique['persuasion_level'], gemini_df_unique['final_strategy'])
chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
print(f"\nâœ“ ì¹´ì´ì œê³± ê²€ì •: Ï‡Â² = {chi2:.3f}, p = {p_value:.4f}, df = {dof}")
if p_value < 0.05:
    print("  â†’ ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ì „ëµ ë¶„í¬ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ ì¡´ì¬")
else:
    print("  â†’ ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ì „ëµ ë¶„í¬ì— ìœ ì˜ë¯¸í•œ ì°¨ì´ ì—†ìŒ")

# íš¨ê³¼ í¬ê¸° (CramÃ©r's V)
n = contingency_table.sum().sum()
cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))
print(f"âœ“ íš¨ê³¼ í¬ê¸° (CramÃ©r's V): {cramers_v:.3f}")

# ì„¤ë“ë ¥ ë†’ì€ ë…¼ì¦ì—ì„œ ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ì „ëµ
high_persuasion_strategies = gemini_df_unique[gemini_df_unique['persuasion_level'] == 'High']['final_strategy'].value_counts(normalize=True) * 100
print(f"\nâœ“ ê³ ì„¤ë“ë ¥ ë…¼ì¦ì—ì„œ ê°€ì¥ ë§ì´ ì‹ë³„ë˜ëŠ” ì „ëµ:")
for strategy, percentage in high_persuasion_strategies.head(5).items():
    print(f"  {strategy}: {percentage:.1f}%")
print()

# --- 6. ê²°ê³¼ ì €ì¥ ---
print("6. ê²°ê³¼ ì €ì¥")
print("-" * 40)

# ë…¼ì¦ë³„ ì „ëµ ìˆ˜ ì €ì¥
strategies_per_argument.to_csv('gemini_strategies_per_argument.csv', index=False, encoding='utf-8-sig')
print("âœ“ ë…¼ì¦ë³„ ì „ëµ ìˆ˜: 'gemini_strategies_per_argument.csv'")

# ë²„ì „ ê°„ ì¼ì¹˜ë„ ì €ì¥
consistency_df.to_csv('gemini_version_consistency.csv', index=False, encoding='utf-8-sig')
print("âœ“ ë²„ì „ ê°„ ì¼ì¹˜ë„: 'gemini_version_consistency.csv'")

# ì„¤ë“ë ¥ë³„ ì „ëµ ë¶„í¬ ì €ì¥
persuasion_strategy_crosstab.to_csv('gemini_persuasion_strategy_distribution.csv', encoding='utf-8-sig')
print("âœ“ ì„¤ë“ë ¥ë³„ ì „ëµ ë¶„í¬: 'gemini_persuasion_strategy_distribution.csv'")

# ì¢…í•© ìš”ì•½ ì €ì¥
summary_stats = {
    'total_arguments': total_arguments,
    'total_versions': total_versions,
    'total_strategies': total_strategies,
    'mean_strategies_per_argument': overall_mean,
    'std_strategies_per_argument': overall_std,
    'mean_jaccard_index': mean_jaccard,
    'std_jaccard_index': std_jaccard,
    'complete_matches_percentage': complete_matches/len(consistency_df)*100,
    'complete_mismatches_percentage': complete_mismatches/len(consistency_df)*100,
    'chi2_statistic': chi2,
    'chi2_p_value': p_value,
    'cramers_v': cramers_v
}

with open('gemini_analysis_summary.json', 'w', encoding='utf-8') as f:
    json.dump(summary_stats, f, indent=2, ensure_ascii=False)
print("âœ“ ì¢…í•© ìš”ì•½: 'gemini_analysis_summary.json'")
print()

# --- 7. ìµœì¢… ê²°ë¡  ---
print("7. ìµœì¢… ê²°ë¡ ")
print("-" * 40)

print(f"ğŸ“Š **Gemini ëª¨ë¸ íŠ¹ì„± ë¶„ì„ ê²°ê³¼**")
print(f"")
print(f"**ì „ëµ ì‹ë³„ íŒ¨í„´:**")
print(f"- ë…¼ì¦ë‹¹ í‰ê·  {overall_mean:.2f}ê°œ ì „ëµ ì‹ë³„")
print(f"- ë²„ì „ ê°„ ì°¨ì´: {'ìœ ì˜í•¨' if p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
print(f"")
print(f"**ì¼ê´€ì„± ë¶„ì„:**")
print(f"- í‰ê·  Jaccard Index: {mean_jaccard:.3f} (ì¤‘ê°„ ìˆ˜ì¤€)")
print(f"- ì™„ì „ ì¼ì¹˜: {complete_matches/len(consistency_df)*100:.1f}%")
print(f"- ì™„ì „ ë¶ˆì¼ì¹˜: {complete_mismatches/len(consistency_df)*100:.1f}%")
print(f"")
print(f"**ì„¤ë“ë ¥-ì „ëµ ê´€ê³„:**")
print(f"- ì„¤ë“ë ¥ ìˆ˜ì¤€ë³„ ì „ëµ ë¶„í¬ ì°¨ì´: {'ìœ ì˜í•¨' if p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")
print(f"- íš¨ê³¼ í¬ê¸°: {cramers_v:.3f} ({'ì‘ìŒ' if cramers_v < 0.3 else 'ì¤‘ê°„' if cramers_v < 0.5 else 'í¼'})")
print(f"")
print(f"**ì—°êµ¬ì  í•¨ì˜:**")
print(f"- Gemini ëª¨ë¸ì€ {overall_mean:.1f}ê°œ ë‚´ì™¸ì˜ ì „ëµì„ ì¼ê´€ë˜ê²Œ ì‹ë³„")
print(f"- ë²„ì „ ê°„ ì¼ì¹˜ë„ëŠ” ì¤‘ê°„ ìˆ˜ì¤€ìœ¼ë¡œ ì™„ì „í•œ ì¼ê´€ì„±ì€ ë¶€ì¡±")
print(f"- ì„¤ë“ë ¥ê³¼ ì „ëµ ë¶„í¬ì˜ ê´€ê³„ëŠ” {'í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨' if p_value < 0.05 else 'í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ'}")

print(f"\n" + "=" * 80)
print("GEMINI ëª¨ë¸ ë¶„ì„ ì™„ë£Œ")
print("=" * 80) 